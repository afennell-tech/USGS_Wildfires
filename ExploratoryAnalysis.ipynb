{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExploratoryAnalysis_Aidan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afennell-tech/USGS_Wildfires/blob/main/ExploratoryAnalysis_Aidan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4dfKRj1n8Lq"
      },
      "source": [
        "# Note\n",
        "The data for [1.88 Million US Wildfires](https://www.kaggle.com/rtatman/188-million-us-wildfires) is very large, so we store the file in google drive, rather than in our github repository. On Kaggle, the file provided is a SQLite database containing information on US wildfires. For the purpose of this project, we will utilize the sqlite3 library. Feel free to download the file to your local machine if you prefer. Click [here](https://drive.google.com/drive/folders/18YlVzuPCf-IXeQQSy0F3H32oG_KHEBhr?usp=sharing) to access the folder containing all data used for this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAdLB2jBmmUA"
      },
      "source": [
        "# Initial Setup:\n",
        "\n",
        "Before running any of the below cells: \n",
        "1. Go to google drive (gdrive)\n",
        "2. Find the 'USGS Wildfires (DS3 SP21 Project)' folder, which should be in the 'Shared with me' section of your gdrive\n",
        "3. Right click on the folder, and select 'Add shortcut to drive'\n",
        "4. Click 'Add shortcut'\n",
        "5. The folder should then appear in 'My Drive' section of gdrive\n",
        "\n",
        "***Users only need to complete the above task once.*** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB_Xc1D2CV6R"
      },
      "source": [
        "# Getting Started: Workspace Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCtiv6PIU4RM"
      },
      "source": [
        "### Mounting Google Drive to Google Colab\n",
        "Note: Any time the runtime is reset, you will need to reauthenticate to mount gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HgrvZ4zHjc4j",
        "outputId": "c82922f2-69bd-4a7d-85cf-199b0e9edd38"
      },
      "source": [
        "from google.colab import drive\n",
        "from os.path import join\n",
        "\n",
        "ROOT = '/content/drive' # default for the drive\n",
        "PROJ = 'MyDrive/USGS_Wildfires_Project_Content' # path to project on Drive\n",
        "PROJ_PATH = join(ROOT, PROJ)\n",
        "DATA_PATH = join(PROJ_PATH, 'data')\n",
        "\n",
        "drive.mount(ROOT) # we mount the drive at /content/drive\n",
        "\n",
        "\"\"\" After executing the above code, the folder 'drive' will appear under \n",
        "the files section. This is the users respective gdrive \"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" After executing the above code, the folder 'drive' will appear under \\nthe files section. This is the users respective gdrive \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaRUgU3x47tn"
      },
      "source": [
        "# Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh9e9uqpLHLP"
      },
      "source": [
        "import sqlite3 # to deal with database \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api\n",
        "\n",
        "\"\"\"\n",
        "Returns a Connection object that represents the input db.\n",
        "\"\"\"\n",
        "def get_sql_connection(sql_file): \n",
        "    return sqlite3.connect(sql_file)\n",
        "\n",
        "\"\"\"\n",
        "Returns a df for table from Connection object.\n",
        "\"\"\"\n",
        "def get_table(table_name, conn):\n",
        "    query = \"Select * from {}\".format(table_name)\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "USGS_DATA_PATH = join(DATA_PATH, 'FPA_FOD_20170508.sqlite')\n",
        "usgs_db = get_sql_connection(USGS_DATA_PATH) # USGS data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNymxSzbOmIA"
      },
      "source": [
        "'''\n",
        "Note: If the below code breaks, make sure that the USGS_DATA_PATH \n",
        "is indeed the correct path to get to the .sqlite file. \n",
        "'''\n",
        "\n",
        "# load fires data\n",
        "fires_df = get_table('fires', usgs_db)\n",
        "# drop OBJECTID; that is specific column for the SQL db\n",
        "fires_df.drop(columns=['OBJECTID'], inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlvlq3_aCDNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea379734-2402-4a80-8b58-162b3a0ced0c"
      },
      "source": [
        "# First, we get some information about the dataframe itself\n",
        "\n",
        "print(f\"There are {len(fires_df)} rows and {len(fires_df.columns)} columns.\")\n",
        "\n",
        "print(f\"List of all column names: {fires_df.columns}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1880465 rows and 38 columns.\n",
            "List of all column names: Index(['FOD_ID', 'FPA_ID', 'SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM',\n",
            "       'NWCG_REPORTING_AGENCY', 'NWCG_REPORTING_UNIT_ID',\n",
            "       'NWCG_REPORTING_UNIT_NAME', 'SOURCE_REPORTING_UNIT',\n",
            "       'SOURCE_REPORTING_UNIT_NAME', 'LOCAL_FIRE_REPORT_ID',\n",
            "       'LOCAL_INCIDENT_ID', 'FIRE_CODE', 'FIRE_NAME',\n",
            "       'ICS_209_INCIDENT_NUMBER', 'ICS_209_NAME', 'MTBS_ID', 'MTBS_FIRE_NAME',\n",
            "       'COMPLEX_NAME', 'FIRE_YEAR', 'DISCOVERY_DATE', 'DISCOVERY_DOY',\n",
            "       'DISCOVERY_TIME', 'STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR', 'CONT_DATE',\n",
            "       'CONT_DOY', 'CONT_TIME', 'FIRE_SIZE', 'FIRE_SIZE_CLASS', 'LATITUDE',\n",
            "       'LONGITUDE', 'OWNER_CODE', 'OWNER_DESCR', 'STATE', 'COUNTY',\n",
            "       'FIPS_CODE', 'FIPS_NAME', 'Shape'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
