{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExploratoryAnalysis_Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afennell-tech/USGS_Wildfires/blob/main/ExploratoryAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4dfKRj1n8Lq"
      },
      "source": [
        "# Note\n",
        "The data for [1.88 Million US Wildfires](https://www.kaggle.com/rtatman/188-million-us-wildfires) is very large, so we store the file in google drive, rather than in our github repository. On Kaggle, the file provided is a SQLite database containing information on US wildfires. For the purpose of this project, we will utilize the sqlite3 library. Feel free to download the file to your local machine if you prefer. Click [here](https://drive.google.com/drive/folders/18YlVzuPCf-IXeQQSy0F3H32oG_KHEBhr?usp=sharing) to access the folder containing all data used for this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAdLB2jBmmUA"
      },
      "source": [
        "# Initial Setup:\n",
        "\n",
        "Before running any of the below cells: \n",
        "1. Go to google drive (gdrive)\n",
        "2. Find the 'USGS Wildfires (DS3 SP21 Project)' folder, which should be in the 'Shared with me' section of your gdrive\n",
        "3. Right click on the folder, and select 'Add shortcut to drive'\n",
        "4. Click 'Add shortcut'\n",
        "5. The folder should then appear in 'My Drive' section of gdrive\n",
        "\n",
        "***Users only need to complete the above task once.*** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB_Xc1D2CV6R"
      },
      "source": [
        "# Getting Started: Workspace Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCtiv6PIU4RM"
      },
      "source": [
        "### Mounting Google Drive to Google Colab\n",
        "Note: Any time the runtime is reset, you will need to reauthenticate to mount gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "HgrvZ4zHjc4j",
        "outputId": "2c1f3923-3a12-4ac0-c5f0-41c21b5a1ff0"
      },
      "source": [
        "from google.colab import drive\n",
        "from os.path import join\n",
        "\n",
        "ROOT = '/content/drive' # default for the drive\n",
        "PROJ = 'MyDrive/USGS_Wildfires_Project_Content' # path to project on Drive\n",
        "PROJ_PATH = join(ROOT, PROJ)\n",
        "DATA_PATH = join(PROJ_PATH, 'data')\n",
        "\n",
        "drive.mount(ROOT) # we mount the drive at /content/drive\n",
        "\n",
        "\"\"\" After executing the above code, the folder 'drive' will appear under \n",
        "the files section. This is the users respective gdrive \"\"\""
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" After executing the above code, the folder 'drive' will appear under \\nthe files section. This is the users respective gdrive \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaRUgU3x47tn"
      },
      "source": [
        "# Exploratory Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NPkKZbq_kE-"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh9e9uqpLHLP"
      },
      "source": [
        "import sqlite3 # to deal with database \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api\n",
        "\n",
        "\"\"\"\n",
        "Returns a Connection object that represents the input db.\n",
        "\"\"\"\n",
        "def get_sql_connection(sql_file): \n",
        "    return sqlite3.connect(sql_file)\n",
        "\n",
        "\"\"\"\n",
        "Returns a df for table from Connection object.\n",
        "\"\"\"\n",
        "def get_table(table_name, conn):\n",
        "    query = \"Select * from {}\".format(table_name)\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "\"\"\"\n",
        "Provided the input dataframe, function prints out the number of values each \n",
        "column takes on and if this number is less than input max_out, the corresponding \n",
        "values are printed as well.\n",
        "\"\"\"\n",
        "def print_col_info(df, max_out=5):\n",
        "    # check if input is valid\n",
        "    assert len(df.columns) > 0\n",
        "    # iterate over each column\n",
        "    for col_name, col in df.items(): \n",
        "        if len(col.value_counts()) <= max_out: \n",
        "            print(f\"\"\"Column name: {col_name}, NaN count: {col.isna().sum()}, \n",
        "            # of non-null values: {len(col.value_counts(dropna=False))}, \n",
        "            distinct values: {col.value_counts().index.tolist()}\"\"\")\n",
        "        else: \n",
        "            print(f\"\"\"Column name: {col_name}, NaN count: {col.isna().sum()}, \n",
        "            # of non-null values: {len(col.value_counts(dropna=False))}\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47rGmSfjGzIO"
      },
      "source": [
        "### Variable Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYrxl4koG-9F"
      },
      "source": [
        "USGS_DATA_PATH = join(DATA_PATH, 'FPA_FOD_20170508.sqlite')\n",
        "usgs_db = get_sql_connection(USGS_DATA_PATH) # USGS data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSxRE7YqJqza"
      },
      "source": [
        "### Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNymxSzbOmIA"
      },
      "source": [
        "'''\n",
        "Note: If the below code breaks, make sure that the USGS_DATA_PATH \n",
        "is indeed the correct path to get to the .sqlite file. \n",
        "'''\n",
        "\n",
        "# load fires data\n",
        "fires_df = get_table('fires', usgs_db)\n",
        "# drop OBJECTID and Shape; these are specific columns for the SQL db\n",
        "fires_df.drop(columns=['OBJECTID', 'Shape'], inplace=True)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlvlq3_aCDNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65187205-d763-4c58-efef-69f0cd62fa0a"
      },
      "source": [
        "# First, we get some info about the dataframe itself\n",
        "\n",
        "print(f\"There are {len(fires_df)} rows and {len(fires_df.columns)} columns.\")\n",
        "\n",
        "print(f\"List of all column names: {fires_df.columns}\")\n",
        "\n",
        "# get more info about the columns themselves (all)\n",
        "print_col_info(fires_df, max_out=20)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1880465 rows and 37 columns.\n",
            "List of all column names: Index(['FOD_ID', 'FPA_ID', 'SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM',\n",
            "       'NWCG_REPORTING_AGENCY', 'NWCG_REPORTING_UNIT_ID',\n",
            "       'NWCG_REPORTING_UNIT_NAME', 'SOURCE_REPORTING_UNIT',\n",
            "       'SOURCE_REPORTING_UNIT_NAME', 'LOCAL_FIRE_REPORT_ID',\n",
            "       'LOCAL_INCIDENT_ID', 'FIRE_CODE', 'FIRE_NAME',\n",
            "       'ICS_209_INCIDENT_NUMBER', 'ICS_209_NAME', 'MTBS_ID', 'MTBS_FIRE_NAME',\n",
            "       'COMPLEX_NAME', 'FIRE_YEAR', 'DISCOVERY_DATE', 'DISCOVERY_DOY',\n",
            "       'DISCOVERY_TIME', 'STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR', 'CONT_DATE',\n",
            "       'CONT_DOY', 'CONT_TIME', 'FIRE_SIZE', 'FIRE_SIZE_CLASS', 'LATITUDE',\n",
            "       'LONGITUDE', 'OWNER_CODE', 'OWNER_DESCR', 'STATE', 'COUNTY',\n",
            "       'FIPS_CODE', 'FIPS_NAME'],\n",
            "      dtype='object')\n",
            "Column name: FOD_ID, NaN count: 0, \n",
            "            # of non-null values: 1880465\n",
            "Column name: FPA_ID, NaN count: 0, \n",
            "            # of non-null values: 1880462\n",
            "Column name: SOURCE_SYSTEM_TYPE, NaN count: 0, \n",
            "            # of non-null values: 3, \n",
            "            distinct values: ['NONFED', 'FED', 'INTERAGCY']\n",
            "Column name: SOURCE_SYSTEM, NaN count: 0, \n",
            "            # of non-null values: 38\n",
            "Column name: NWCG_REPORTING_AGENCY, NaN count: 0, \n",
            "            # of non-null values: 11, \n",
            "            distinct values: ['ST/C&L', 'FS', 'BIA', 'BLM', 'IA', 'NPS', 'FWS', 'TRIBE', 'DOD', 'BOR', 'DOE']\n",
            "Column name: NWCG_REPORTING_UNIT_ID, NaN count: 0, \n",
            "            # of non-null values: 1640\n",
            "Column name: NWCG_REPORTING_UNIT_NAME, NaN count: 0, \n",
            "            # of non-null values: 1635\n",
            "Column name: SOURCE_REPORTING_UNIT, NaN count: 0, \n",
            "            # of non-null values: 4992\n",
            "Column name: SOURCE_REPORTING_UNIT_NAME, NaN count: 0, \n",
            "            # of non-null values: 4441\n",
            "Column name: LOCAL_FIRE_REPORT_ID, NaN count: 1459286, \n",
            "            # of non-null values: 13509\n",
            "Column name: LOCAL_INCIDENT_ID, NaN count: 820821, \n",
            "            # of non-null values: 565915\n",
            "Column name: FIRE_CODE, NaN count: 1555636, \n",
            "            # of non-null values: 172447\n",
            "Column name: FIRE_NAME, NaN count: 957189, \n",
            "            # of non-null values: 493634\n",
            "Column name: ICS_209_INCIDENT_NUMBER, NaN count: 1854748, \n",
            "            # of non-null values: 22738\n",
            "Column name: ICS_209_NAME, NaN count: 1854748, \n",
            "            # of non-null values: 19574\n",
            "Column name: MTBS_ID, NaN count: 1869462, \n",
            "            # of non-null values: 10482\n",
            "Column name: MTBS_FIRE_NAME, NaN count: 1869462, \n",
            "            # of non-null values: 8134\n",
            "Column name: COMPLEX_NAME, NaN count: 1875282, \n",
            "            # of non-null values: 1417\n",
            "Column name: FIRE_YEAR, NaN count: 0, \n",
            "            # of non-null values: 24\n",
            "Column name: DISCOVERY_DATE, NaN count: 0, \n",
            "            # of non-null values: 8766\n",
            "Column name: DISCOVERY_DOY, NaN count: 0, \n",
            "            # of non-null values: 366\n",
            "Column name: DISCOVERY_TIME, NaN count: 882638, \n",
            "            # of non-null values: 1441\n",
            "Column name: STAT_CAUSE_CODE, NaN count: 0, \n",
            "            # of non-null values: 13, \n",
            "            distinct values: [5.0, 9.0, 7.0, 1.0, 13.0, 2.0, 4.0, 8.0, 3.0, 6.0, 11.0, 10.0, 12.0]\n",
            "Column name: STAT_CAUSE_DESCR, NaN count: 0, \n",
            "            # of non-null values: 13, \n",
            "            distinct values: ['Debris Burning', 'Miscellaneous', 'Arson', 'Lightning', 'Missing/Undefined', 'Equipment Use', 'Campfire', 'Children', 'Smoking', 'Railroad', 'Powerline', 'Fireworks', 'Structure']\n",
            "Column name: CONT_DATE, NaN count: 891531, \n",
            "            # of non-null values: 8761\n",
            "Column name: CONT_DOY, NaN count: 891531, \n",
            "            # of non-null values: 367\n",
            "Column name: CONT_TIME, NaN count: 972173, \n",
            "            # of non-null values: 1442\n",
            "Column name: FIRE_SIZE, NaN count: 0, \n",
            "            # of non-null values: 13637\n",
            "Column name: FIRE_SIZE_CLASS, NaN count: 0, \n",
            "            # of non-null values: 7, \n",
            "            distinct values: ['B', 'A', 'C', 'D', 'E', 'F', 'G']\n",
            "Column name: LATITUDE, NaN count: 0, \n",
            "            # of non-null values: 894061\n",
            "Column name: LONGITUDE, NaN count: 0, \n",
            "            # of non-null values: 997536\n",
            "Column name: OWNER_CODE, NaN count: 0, \n",
            "            # of non-null values: 16, \n",
            "            distinct values: [14.0, 8.0, 5.0, 2.0, 13.0, 1.0, 7.0, 3.0, 4.0, 9.0, 6.0, 12.0, 15.0, 11.0, 10.0, 0.0]\n",
            "Column name: OWNER_DESCR, NaN count: 0, \n",
            "            # of non-null values: 16, \n",
            "            distinct values: ['MISSING/NOT SPECIFIED', 'PRIVATE', 'USFS', 'BIA', 'STATE OR PRIVATE', 'BLM', 'STATE', 'NPS', 'FWS', 'TRIBAL', 'OTHER FEDERAL', 'MUNICIPAL/LOCAL', 'UNDEFINED FEDERAL', 'COUNTY', 'BOR', 'FOREIGN']\n",
            "Column name: STATE, NaN count: 0, \n",
            "            # of non-null values: 52\n",
            "Column name: COUNTY, NaN count: 678148, \n",
            "            # of non-null values: 3456\n",
            "Column name: FIPS_CODE, NaN count: 678148, \n",
            "            # of non-null values: 286\n",
            "Column name: FIPS_NAME, NaN count: 678148, \n",
            "            # of non-null values: 1699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW1DCyA6oHQW"
      },
      "source": [
        "### For now, we only care about exploring the following variables: \n",
        "OWNER_DESCR, FIRE_SIZE, FIRE_SIZE_CLASS, FIRE_YEAR, DISCOVERY_DATE, STAT_CAUSE_DESCR, LATITUDE, LONGITUDE, STATE, COUNTY\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3B0i9_kow2r"
      },
      "source": [
        "\"\"\"\n",
        "Subset fires_df to explore the above columns. Find necessary and informative\n",
        "descriptive statistics, clean the data, make simple visualizations, run simple\n",
        "regressions, etc. Just do whatever feels right so we can begin to understand \n",
        "what steps to take moving forward. \n",
        "\"\"\"\n",
        "\n",
        "# ADD CODE HERE - TODO"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}